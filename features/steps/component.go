package steps

import (
	"context"
	"fmt"
	"os"
	"os/signal"
	"sync"
	"syscall"
	"testing"
	"time"

	componenttest "github.com/ONSdigital/dp-component-test"
	kafka "github.com/ONSdigital/dp-kafka/v3"
	"github.com/ONSdigital/dp-search-data-extractor/config"
	"github.com/ONSdigital/dp-search-data-extractor/models"
	"github.com/ONSdigital/dp-search-data-extractor/service"
	"github.com/ONSdigital/log.go/v2/log"
	"github.com/maxcnunes/httpfake"
)

const (
	ComponentTestGroup    = "component-test" // kafka group name for the component test consumer
	DrainTopicTimeout     = 5 * time.Second  // maximum time to wait for a topic to be drained
	DrainTopicMaxMessages = 1000             // maximum number of messages that will be drained from a topic
	WaitEventTimeout      = 15 * time.Second // maximum time that the component test consumer will wait for a kafka event
)

var (
	BuildTime = "1625046891"
	GitCommit = "7434fe334d9f51b7239f978094ea29d10ac33b16"
	Version   = ""
)

type Component struct {
	componenttest.ErrorFeature
	DatasetAPI       *httpfake.HTTPFake   // Dataset API mock at HTTP level
	Zebedee          *httpfake.HTTPFake   // Zebedee mock at HTTP level
	KafkaProducer    kafka.IProducer      // To producer messages to the topic consumed by the service under test
	KafkaConsumer    kafka.IConsumerGroup // To consume messages from the topic produced by the service under test
	inputData        models.ZebedeeData   // TODO remove and replace with godoc
	errorChan        chan error
	svc              *service.Service
	cfg              *config.Config
	wg               *sync.WaitGroup
	signals          chan os.Signal
	waitEventTimeout time.Duration
	testETag         string
	ctx              context.Context
}

func NewComponent(t *testing.T) *Component {
	return &Component{
		DatasetAPI:       httpfake.New(),
		Zebedee:          httpfake.New(),
		errorChan:        make(chan error),
		waitEventTimeout: WaitEventTimeout,
		wg:               &sync.WaitGroup{},
		testETag:         "13c7791bafdbaaf5e6660754feb1a58cd6aaa892",
		ctx:              context.Background(),
	}
}

// initService initialises the server, the mocks and waits for the dependencies to be ready
func (c *Component) initService(ctx context.Context) error {
	// register interrupt signals
	c.signals = make(chan os.Signal, 1)
	signal.Notify(c.signals, syscall.SIGINT, syscall.SIGTERM)

	// Read config
	cfg, err := config.Get()
	if err != nil {
		return fmt.Errorf("failed to get config: %w", err)
	}

	cfg.DatasetAPIURL = c.DatasetAPI.ResolveURL("")
	cfg.ZebedeeURL = c.Zebedee.ResolveURL("")

	log.Info(ctx, "config used by component tests", log.Data{"cfg": cfg})

	// KafkaProducer for triggering test events
	if c.KafkaProducer, err = kafka.NewProducer(
		ctx,
		&kafka.ProducerConfig{
			BrokerAddrs:       cfg.Kafka.Addr,
			Topic:             cfg.Kafka.ContentUpdatedTopic,
			MinBrokersHealthy: &cfg.Kafka.ProducerMinBrokersHealthy,
			KafkaVersion:      &cfg.Kafka.Version,
			MaxMessageBytes:   &cfg.Kafka.MaxBytes,
		},
	); err != nil {
		return fmt.Errorf("error creating kafka producer: %w", err)
	}

	// KafkaConsumer for receiving produced events
	// (expected to be generated by the service under test)
	// use kafkaOldest to make sure we consume all the messages
	kafkaOffset := kafka.OffsetOldest
	if c.KafkaConsumer, err = kafka.NewConsumerGroup(
		ctx,
		&kafka.ConsumerGroupConfig{
			BrokerAddrs:       cfg.Kafka.Addr,
			Topic:             cfg.Kafka.ProducerTopic,
			GroupName:         ComponentTestGroup,
			MinBrokersHealthy: &cfg.Kafka.ConsumerMinBrokersHealthy,
			KafkaVersion:      &cfg.Kafka.Version,
			Offset:            &kafkaOffset,
		},
	); err != nil {
		return fmt.Errorf("error creating kafka consumer: %w", err)
	}

	// start consumer group
	if err := c.KafkaConsumer.Start(); err != nil {
		return fmt.Errorf("error starting kafka consumer: %w", err)
	}

	// start kafka logging go-routines
	c.KafkaConsumer.LogErrors(ctx)
	c.KafkaProducer.LogErrors(ctx)

	// Create service and initialise it
	c.svc = service.New()
	if err = c.svc.Init(ctx, cfg, BuildTime, GitCommit, Version); err != nil {
		return fmt.Errorf("unexpected service Init error in NewComponent: %w", err)
	}

	c.cfg = cfg

	// wait for producer to be initialised and consumer to be in consuming state
	<-c.KafkaProducer.Channels().Initialised
	log.Info(ctx, "component-test kafka producer initialised")
	c.KafkaConsumer.StateWait(kafka.Consuming)
	log.Info(ctx, "component-test kafka consumer is in consuming state")

	return nil
}

func (c *Component) startService(ctx context.Context) error {
	if err := c.svc.Start(ctx, c.errorChan); err != nil {
		return fmt.Errorf("unexpected error while starting service: %w", err)
	}

	c.wg.Add(1)
	go func() {
		defer c.wg.Done()

		// blocks until an os interrupt or a fatal error occurs
		select {
		case err := <-c.errorChan:
			if errClose := c.svc.Close(ctx); errClose != nil {
				log.Warn(ctx, "error closing server during error handing", log.Data{"close_error": errClose})
			}
			panic(fmt.Errorf("unexpected error received from errorChan: %w", err))
		case sig := <-c.signals:
			log.Info(ctx, "os signal received", log.Data{"signal": sig})
		}

		if err := c.svc.Close(ctx); err != nil {
			panic(fmt.Errorf("unexpected error during service graceful shutdown: %w", err))
		}
	}()

	return nil
}

// Close kills the application under test, drains all topics, and then it shuts down the testing consumer and producer.
func (c *Component) Close() {
	// kill application
	c.signals <- os.Interrupt

	// wait for graceful shutdown to finish (or timeout)
	c.wg.Wait()

	// stop listening to consumer, waiting for any in-flight message to be committed
	if err := c.KafkaConsumer.StopAndWait(); err != nil {
		log.Error(c.ctx, "error stopping component-test kafka consumer", err)
	}

	// close producer
	if err := c.KafkaProducer.Close(c.ctx); err != nil {
		log.Error(c.ctx, "error closing component-test kafka producer", err)
	}

	// close consumer
	if err := c.KafkaConsumer.Close(c.ctx); err != nil {
		log.Error(c.ctx, "error closing component-test kafka consumer", err)
	}

	log.Info(c.ctx, "[DEBUG] Sleeping")
	time.Sleep(time.Second)

	// drain topics in parallel
	kafka.DrainTopics(c.ctx,
		&kafka.DrainTopicConfig{
			BrokerAddrs:  c.cfg.Kafka.Addr,
			KafkaVersion: &c.cfg.Kafka.Version,
			Timeout:      DrainTopicTimeout,
			BatchSize:    DrainTopicMaxMessages,
		},
		&kafka.DrainTopicInput{
			Topic:     c.cfg.Kafka.ContentUpdatedTopic,
			GroupName: c.cfg.Kafka.ContentUpdatedGroup,
		},
		// &kafka.DrainTopicInput{
		// 	Topic:     c.cfg.Kafka.ProducerTopic,
		// 	GroupName: ComponentTestGroup,
		// },
	)

	// drain topics in parallel
	kafka.DrainTopics(c.ctx,
		&kafka.DrainTopicConfig{
			BrokerAddrs:  c.cfg.Kafka.Addr,
			KafkaVersion: &c.cfg.Kafka.Version,
			Timeout:      DrainTopicTimeout,
			BatchSize:    DrainTopicMaxMessages,
		},
		// &kafka.DrainTopicInput{
		// 	Topic:     c.cfg.Kafka.ContentUpdatedTopic,
		// 	GroupName: c.cfg.Kafka.ContentUpdatedGroup,
		// },
		&kafka.DrainTopicInput{
			Topic:     c.cfg.Kafka.ProducerTopic,
			GroupName: ComponentTestGroup,
		},
	)
}

// Reset re-initialises the service under test and the api mocks.
// Note that the service under test should not be started yet
// to prevent race conditions if it tries to call un-initialised dependencies (steps)
func (c *Component) Reset() error {
	if err := c.initService(c.ctx); err != nil {
		return fmt.Errorf("failed to initialise service: %w", err)
	}

	c.DatasetAPI.Reset()
	c.Zebedee.Reset()

	return nil
}
